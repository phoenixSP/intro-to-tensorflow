{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDeyeSt7mTdNEdzKjPpcEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phoenixSP/intro-to-tensorflow/blob/master/week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v769gX9majG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d800fb8b-b807-4e78-846f-0a2eaad453d1"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwS8Qn-DpTFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dc6651d-f98c-4548-e525-28c80e399aee"
      },
      "source": [
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 29us/sample - loss: 0.3567 - acc: 0.8721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h49ZK6BI6XrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvnDOaLupe56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "d291ed91-f403-406f-b968-7033d995852d"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.4507 - acc: 0.8367\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.3041 - acc: 0.8886\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.2562 - acc: 0.9054\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.2227 - acc: 0.9170\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.1968 - acc: 0.9262\n",
            "10000/10000 [==============================] - 4s 424us/sample - loss: 0.2553 - acc: 0.9074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_kMVuOQzg0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c39f1b78-8c76-4ef4-f48c-ae51a3ef939d"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv3j2LExzqIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "25f9f8aa-25c8-4da9-b338-4309f041ccdd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "CONVOLUTION_NUMBER = 1\n",
        "\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ollPsnlb1Alq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "0fefe4a9-25d1-4f77-b9b2-e62f9ec6ab8c"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 44s 732us/sample - loss: 0.4764 - acc: 0.8263\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 44s 729us/sample - loss: 0.3203 - acc: 0.8817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 44s 730us/sample - loss: 0.2738 - acc: 0.8982\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 43s 721us/sample - loss: 0.2428 - acc: 0.9098\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 43s 719us/sample - loss: 0.2173 - acc: 0.9173\n",
            "10000/10000 [==============================] - 2s 250us/sample - loss: 0.2718 - acc: 0.8996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUEfa58_3Pe6",
        "colab_type": "text"
      },
      "source": [
        "The accuracy decreased as we reduced the number of feature extractor each layer. See https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional for more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vasc-MkX3Bh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "d07ba7df-16f0-4724-aff6-a2b1389c880c"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 11, 11, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               51328     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 55,098\n",
            "Trainable params: 55,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 30s 492us/sample - loss: 0.5110 - acc: 0.8142\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 30s 493us/sample - loss: 0.3488 - acc: 0.8731\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 30s 499us/sample - loss: 0.3057 - acc: 0.8878\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 30s 504us/sample - loss: 0.2754 - acc: 0.8985\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 30s 505us/sample - loss: 0.2548 - acc: 0.9050\n",
            "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2859 - acc: 0.8944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0PURmth5RmR",
        "colab_type": "text"
      },
      "source": [
        "Further decrease in training accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsGMLJMK5QyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "8d1f114a-6bb6-4d61-e47a-7b3781d82501"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2704)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               346240    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 347,690\n",
            "Trainable params: 347,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 440us/sample - loss: 0.4095 - acc: 0.8551\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 27s 444us/sample - loss: 0.2811 - acc: 0.8980\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 438us/sample - loss: 0.2364 - acc: 0.9125\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 27s 446us/sample - loss: 0.2066 - acc: 0.9226\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 27s 445us/sample - loss: 0.1808 - acc: 0.9336\n",
            "10000/10000 [==============================] - 2s 197us/sample - loss: 0.2577 - acc: 0.9078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq3go7ln72WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc')>0.79):\n",
        "          print(\"\\nReached 79% accuracy so cancelling training!\")\n",
        "          self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "# YOUR CODE SHOULD END HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zg1_dS43Ogf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "7e6c21df-dd9e-42ff-a02e-4e7fc21a2bbd"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 16)          2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               2176      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 8,266\n",
            "Trainable params: 8,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.7156 - acc: 0.7349\n",
            "Epoch 2/5\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.5094 - acc: 0.8146\n",
            "Reached 79% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.5094 - acc: 0.8146\n",
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.5239 - acc: 0.8115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zv0bk4V7Uv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}